{
 "cells": [
  {
   "cell_type": "code",
   "id": "86be9fbe31b4dfcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:47.471240Z",
     "start_time": "2025-01-11T10:36:47.465534Z"
    }
   },
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    "    Image,\n",
    ")\n",
    "import vertexai\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "import re\n",
    "from typing import List, Tuple"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:48.885026Z",
     "start_time": "2025-01-11T10:36:48.879391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_credentials():\n",
    "    # Search \"How to Use Vertex AI API in Google Cloud\" video in Youtube at timestamp 2:40 for tutorial how to download this json. provide the path of the downloaded json here.\n",
    "    service_account_json_path = \"service_account.json\"\n",
    "    credentials = Credentials.from_service_account_file(\n",
    "        service_account_json_path,\n",
    "        scopes=['https://www.googleapis.com/auth/cloud-platform']) # Fixed url, dont change !\n",
    "    if credentials.expired:\n",
    "        credentials.refresh(Request())\n",
    "    return credentials"
   ],
   "id": "f8c9a1797012e095",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:50.357752Z",
     "start_time": "2025-01-11T10:36:50.354655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_vertex_ai(project: str, location: str):\n",
    "    vertexai.init(project=project, location=location, credentials=get_credentials())"
   ],
   "id": "7f101783cb5728fa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:51.963309Z",
     "start_time": "2025-01-11T10:36:51.960291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_cv_model(base_model_id: str):\n",
    "    # system_instruction = Explation to the model to exaplin who he is, before it is given a specific task.\n",
    "    cv_model = GenerativeModel(\n",
    "        base_model_id,\n",
    "        system_instruction=[\n",
    "            \"You are a highly skilled security guard working at a retail store.\",\n",
    "            \"Your main responsibility is to monitor customer behavior and identify potential shoplifting activities.\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return cv_model"
   ],
   "id": "80ac351a04772720",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:53.314478Z",
     "start_time": "2025-01-11T10:36:53.310913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_prompt_model(base_model_id: str):\n",
    "    prompt_model = GenerativeModel(\n",
    "        base_model_id,\n",
    "        system_instruction=[\n",
    "            \"As an assistant to the cv_model, your primary function is to help it perform its duties as a virtual security guard in a retail environment.\",\n",
    "            \"Your role is to craft detailed prompts that will enable the cv_model to monitor customer behavior accurately and identify potential shoplifting activities by breaking down these complex tasks into smaller, more manageable steps.\",\n",
    "            \"This approach is similar to how a human would tackle a complex problem, enhancing the cv_modelâ€™s ability to process and analyze situations effectively.\",\n",
    "            \"Here's how you might construct a structured prompt for the cv_model:\",\n",
    "            \"Imagine you are a highly skilled security guard working at a retail store.\",\n",
    "            \"Your main responsibility is to monitor customer behavior and identify potential shoplifting activities.\",\n",
    "            \"Break down your observation process into the following steps:\",\n",
    "            \"Initial Surveillance: Scan the store entrance and aisles.\",\n",
    "            \"Look for customers who avoid eye contact with staff or surveillance cameras, or those carrying empty bags.\",\n",
    "            \"Detailed Observation: Focus on individuals who exhibit unusual or suspicious movements, such as concealing items or lingering in certain areas without a clear purpose.\",\n",
    "            \"Behavior Analysis: Note behaviors like repeatedly entering and exiting the store without purchases, or carrying fuller bags after visiting the store.\",\n",
    "            \"Pay special attention to customers who take items and do not head towards the checkout counters, as this could indicate an intent to shoplift.\",\n",
    "            \"Situation Assessment: Combine the observed details to assess whether these behaviors cumulatively suggest a potential for shoplifting.\",\n",
    "            \"Reporting: Describe in detail the specific behaviors, the exact locations within the store, and articulate why these actions may suggest potential shoplifting.\",\n",
    "            \"Ensure that your report is polite and professional, focusing on behavior rather than personal attributes to avoid bias and false accusations.\",\n",
    "            \"Each step should guide you through the task, making it easier to process complex information and make accurate judgments.\",\n",
    "            \"This structured approach will help you enhance your observational techniques, distinguishing effectively between normal customer behavior and potential security risks.\",\n",
    "            \"Your prompts should be clear, instructive, and carefully designed to assist the cv_model in processing and reporting information efficiently, by breaking complex observations into smaller analytical tasks.\",\n",
    "            \"Each prompt should refine the cv_model's ability to observe and evaluate with precision.\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return prompt_model"
   ],
   "id": "75aaf2b438758a65",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:55.662779Z",
     "start_time": "2025-01-11T10:36:55.658718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_analysis_model(base_model_id: str):\n",
    "    analysis_model = GenerativeModel(\n",
    "        base_model_id,\n",
    "        system_instruction=[\n",
    "            \"As an advanced analytical model, your main function is to process the observations provided by the cv_model and the corresponding video footage to determine the likelihood of shoplifting activity.\",\n",
    "            \"Your role involves analyzing the video and the detailed observations to validate the presence of shoplifting behaviors and calculate a confidence score between 0 and 1.\",\n",
    "            \"You must provide two outputs: a Boolean value (True if shoplifting is detected, False otherwise) and a numerical confidence score indicating the certainty of your analysis.\",\n",
    "            \"Utilize advanced video analysis techniques such as behavior pattern recognition, object detection, and movement tracking to reassess the scenes described by the cv_model.\",\n",
    "            \"Your output should clearly state whether shoplifting is likely or not, accompanied by a confidence score that quantifies the certainty of this determination.\",\n",
    "            \"Ensure your analysis is robust, fair, and free from bias, focusing strictly on the actions depicted in the video.\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return analysis_model"
   ],
   "id": "16e351e06c835bc9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:57.105520Z",
     "start_time": "2025-01-11T10:36:57.100313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_generation_config():\n",
    "    # Set model parameters\n",
    "    # need to investigate more about what each parameter does and its effect\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.9,\n",
    "        top_p=1.0,\n",
    "        top_k=32,\n",
    "        candidate_count=1,\n",
    "        max_output_tokens=8192,\n",
    "    )\n",
    "\n",
    "    return generation_config"
   ],
   "id": "a0f653e2c08c9c9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:58.191017Z",
     "start_time": "2025-01-11T10:36:58.186750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_safety_settings():\n",
    "    # Set safety settings.\n",
    "    # Dont know what does it mean, need to investigate\n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    }\n",
    "\n",
    "    return safety_settings"
   ],
   "id": "1b732415769a587f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:36:59.209695Z",
     "start_time": "2025-01-11T10:36:59.206396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_response_from_prompt_model(prompt_model, generation_config, safety_settings, video_file) -> str:\n",
    "    prompt_model_prompt = \"Generate a prompt that instructs the cv_model to effectively monitor customer behavior and identify potential shoplifting activities in a retail environment in the attached video, following the 'chain of thought' method to break down complex tasks into smaller, more manageable steps.\"\n",
    "    #uri is the place of the video in your bucket\n",
    "    contents = [video_file, prompt_model_prompt]\n",
    "    # Prompt the model to generate content\n",
    "    prompt_model_response = prompt_model.generate_content(\n",
    "        contents,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "    )\n",
    "\n",
    "    return prompt_model_response.text"
   ],
   "id": "e96e2e43d9f88efd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:37:00.280418Z",
     "start_time": "2025-01-11T10:37:00.277256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_response_from_cv_model(cv_model, generation_config, safety_settings, video_file, prompt_model_response: str):\n",
    "    # Set contents to send to the model\n",
    "    contents = [video_file, prompt_model_response]\n",
    "    # Prompt the model to generate content\n",
    "    cv_model_response = cv_model.generate_content(\n",
    "        contents,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "    )\n",
    "\n",
    "    return cv_model_response.text"
   ],
   "id": "541b2a3697269694",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:37:01.800283Z",
     "start_time": "2025-01-11T10:37:01.794770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_response_from_analysis_model(analysis_model, generation_config, safety_settings, video_file, cv_model_response: str):\n",
    "    # Prompt to instruct the analysis_model to perform its task\n",
    "    analysis_model_prompt = \"Analyze the provided video and cv_model's observations to assess the likelihood of shoplifting. Determine if shoplifting has occurred and provide outputs labeled 'Shoplifting Detected' for the Boolean determination and 'Confidence Level' for the confidence score between 0 and 1.\"\n",
    "    analysis_model_prompt += \"The cv_model response here is: \" + cv_model_response\n",
    "    contents = [video_file, analysis_model_prompt]\n",
    "    # Prompt the model to generate content\n",
    "    analysis_model_response = analysis_model.generate_content(\n",
    "        contents,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "    )\n",
    "\n",
    "    return analysis_model_response.text"
   ],
   "id": "24eea6b1ed6b6475",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:37:03.313124Z",
     "start_time": "2025-01-11T10:37:03.303258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_values_from_string(response_str: str) -> Tuple[bool, float]:\n",
    "    response_str = response_str.lower()\n",
    "    # Finding the start index of 'Shoplifting Detected' and extracting the Boolean value\n",
    "    start_detected = response_str.find(\"shoplifting detected\")\n",
    "    if start_detected != -1:  # Check if the substring was found\n",
    "        true_index = response_str.find(\"true\", start_detected, start_detected+len(\"shoplifting detected\")+10)\n",
    "        false_index = response_str.find(\"false\", start_detected, start_detected+len(\"shoplifting detected\")+10)\n",
    "\n",
    "        # Convert the extracted value to Boolean\n",
    "        if true_index != -1:\n",
    "            shoplifting_detected = True\n",
    "        elif false_index != -1:\n",
    "            shoplifting_detected = False\n",
    "        else:\n",
    "            raise ValueError(\"Invalid format for 'Shoplifting Detected'\")\n",
    "    else:\n",
    "        raise ValueError(\"'Shoplifting Detected' not found in the string\")\n",
    "\n",
    "    # Finding the start index of 'Confidence Level' and extracting the float value\n",
    "    start_confidence = response_str.find(\"confidence level\")\n",
    "    if start_confidence != -1:  # Check if the substring was found\n",
    "        end_confidence = start_confidence + len(\"confidence level\") + 10\n",
    "        confidence_level_str = response_str[start_confidence:end_confidence].strip()\n",
    "        confidence_level = extract_float(confidence_level_str)\n",
    "    else:\n",
    "        raise ValueError(\"'Confidence Level' not found in the string\")\n",
    "\n",
    "    return shoplifting_detected, confidence_level\n",
    "\n",
    "def extract_float(s: str) -> float | None:\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', s)\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return None"
   ],
   "id": "cee5eeea6489c2a7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:37:05.526599Z",
     "start_time": "2025-01-11T10:37:05.523260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def should_continue(confidence_levels: List[float], max_tries: int) -> bool:\n",
    "    return confidence_levels[-1] < 0.9 and len(confidence_levels) < max_tries and not has_reached_plateau(confidence_levels)\n",
    "\n",
    "def has_reached_plateau(values: List[float]) -> bool:\n",
    "    if len(values) < 3:\n",
    "        return False\n",
    "    return values[-1] == values[-2] == values[-3]"
   ],
   "id": "1bf409fb7861597",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T10:40:32.839465Z",
     "start_time": "2025-01-11T10:40:10.025474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    init_vertex_ai(project=\"astral-sunbeam-443219-p5\", location=\"us-central1\")\n",
    "    MODEL_ID = \"gemini-1.5-flash-002\"  # any google model, search here for more models https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro-vision?inv=1&invt=AblIyQ&project=datamind-production\n",
    "    cv_model = get_cv_model(MODEL_ID)\n",
    "    prompt_model = get_prompt_model(MODEL_ID)\n",
    "    analysis_model = get_analysis_model(MODEL_ID)\n",
    "    generation_config = get_generation_config()\n",
    "    safety_settings = get_safety_settings()\n",
    "    confidence_levels = [0]\n",
    "    shoplifting_detected = \"false\"\n",
    "    cv_model_response = \"\"\n",
    "    analysis_model_response = \"\"\n",
    "    max_tries = 10\n",
    "\n",
    "    while should_continue(confidence_levels, max_tries):\n",
    "        video_file = Part.from_uri(uri=\"gs://example_bucket_final_project/43dd8387-28ad-4a64-bda1-9c566c526b82.MP4\", mime_type=\"video/mp4\")\n",
    "        prompt_model_response = get_response_from_prompt_model(prompt_model, generation_config, safety_settings, video_file)\n",
    "        cv_model_response = get_response_from_cv_model(cv_model, generation_config, safety_settings, video_file, prompt_model_response)\n",
    "        analysis_model_response = get_response_from_analysis_model(analysis_model, generation_config, safety_settings, video_file, cv_model_response)\n",
    "        shoplifting_detected, confidence_level = extract_values_from_string(analysis_model_response)\n",
    "        print(f\"Shoplifting Detected: {shoplifting_detected}\")\n",
    "        print(f\"Confidence Level: {confidence_level}\")\n",
    "        confidence_levels.append(confidence_level)\n",
    "\n",
    "    print (\"Shoplifting Detected: \", shoplifting_detected)\n",
    "    print (\"Confidence Level: \", confidence_levels[-1])\n",
    "    print(\"The cv model response is: \", cv_model_response)\n",
    "    print(\"The analysis model response is: \", analysis_model_response)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m prompt_model_response \u001B[38;5;241m=\u001B[39m get_response_from_prompt_model(prompt_model, generation_config, safety_settings, video_file)\n\u001B[1;32m     18\u001B[0m cv_model_response \u001B[38;5;241m=\u001B[39m get_response_from_cv_model(cv_model, generation_config, safety_settings, video_file, prompt_model_response)\n\u001B[0;32m---> 19\u001B[0m analysis_model_response \u001B[38;5;241m=\u001B[39m get_response_from_analysis_model(analysis_model, generation_config, safety_settings, video_file, cv_model_response)\n\u001B[1;32m     20\u001B[0m shoplifting_detected, confidence_level \u001B[38;5;241m=\u001B[39m extract_values_from_string(analysis_model_response)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShoplifting Detected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshoplifting_detected\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[14], line 7\u001B[0m, in \u001B[0;36mget_response_from_analysis_model\u001B[0;34m(analysis_model, generation_config, safety_settings, video_file, cv_model_response)\u001B[0m\n\u001B[1;32m      5\u001B[0m contents \u001B[38;5;241m=\u001B[39m [video_file, analysis_model_prompt]\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Prompt the model to generate content\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m analysis_model_response \u001B[38;5;241m=\u001B[39m analysis_model\u001B[38;5;241m.\u001B[39mgenerate_content(\n\u001B[1;32m      8\u001B[0m     contents,\n\u001B[1;32m      9\u001B[0m     generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[1;32m     10\u001B[0m     safety_settings\u001B[38;5;241m=\u001B[39msafety_settings,\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m analysis_model_response\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:654\u001B[0m, in \u001B[0;36m_GenerativeModel.generate_content\u001B[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001B[0m\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_content_streaming(\n\u001B[1;32m    646\u001B[0m         contents\u001B[38;5;241m=\u001B[39mcontents,\n\u001B[1;32m    647\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    651\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m    652\u001B[0m     )\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 654\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_content(\n\u001B[1;32m    655\u001B[0m         contents\u001B[38;5;241m=\u001B[39mcontents,\n\u001B[1;32m    656\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[1;32m    657\u001B[0m         safety_settings\u001B[38;5;241m=\u001B[39msafety_settings,\n\u001B[1;32m    658\u001B[0m         tools\u001B[38;5;241m=\u001B[39mtools,\n\u001B[1;32m    659\u001B[0m         tool_config\u001B[38;5;241m=\u001B[39mtool_config,\n\u001B[1;32m    660\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m    661\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:779\u001B[0m, in \u001B[0;36m_GenerativeModel._generate_content\u001B[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001B[0m\n\u001B[1;32m    752\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generates content.\u001B[39;00m\n\u001B[1;32m    753\u001B[0m \n\u001B[1;32m    754\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    769\u001B[0m \u001B[38;5;124;03m    A single GenerationResponse object\u001B[39;00m\n\u001B[1;32m    770\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    771\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_request(\n\u001B[1;32m    772\u001B[0m     contents\u001B[38;5;241m=\u001B[39mcontents,\n\u001B[1;32m    773\u001B[0m     generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    777\u001B[0m     labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m    778\u001B[0m )\n\u001B[0;32m--> 779\u001B[0m gapic_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prediction_client\u001B[38;5;241m.\u001B[39mgenerate_content(request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_response(gapic_response)\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2159\u001B[0m, in \u001B[0;36mPredictionServiceClient.generate_content\u001B[0;34m(self, request, model, contents, retry, timeout, metadata)\u001B[0m\n\u001B[1;32m   2156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_universe_domain()\n\u001B[1;32m   2158\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[0;32m-> 2159\u001B[0m response \u001B[38;5;241m=\u001B[39m rpc(\n\u001B[1;32m   2160\u001B[0m     request,\n\u001B[1;32m   2161\u001B[0m     retry\u001B[38;5;241m=\u001B[39mretry,\n\u001B[1;32m   2162\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m   2163\u001B[0m     metadata\u001B[38;5;241m=\u001B[39mmetadata,\n\u001B[1;32m   2164\u001B[0m )\n\u001B[1;32m   2166\u001B[0m \u001B[38;5;66;03m# Done; return the response.\u001B[39;00m\n\u001B[1;32m   2167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001B[0m, in \u001B[0;36m_GapicCallable.__call__\u001B[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m compression\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:76\u001B[0m, in \u001B[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(callable_)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merror_remapped_callable\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 76\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m callable_(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m grpc\u001B[38;5;241m.\u001B[39mRpcError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     78\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mfrom_grpc_error(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/grpc/_channel.py:1178\u001B[0m, in \u001B[0;36m_UnaryUnaryMultiCallable.__call__\u001B[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[0m\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m   1167\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1168\u001B[0m     request: Any,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1173\u001B[0m     compression: Optional[grpc\u001B[38;5;241m.\u001B[39mCompression] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1174\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m   1175\u001B[0m     (\n\u001B[1;32m   1176\u001B[0m         state,\n\u001B[1;32m   1177\u001B[0m         call,\n\u001B[0;32m-> 1178\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blocking(\n\u001B[1;32m   1179\u001B[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001B[1;32m   1180\u001B[0m     )\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _end_unary_response_blocking(state, call, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/envs/final_project/lib/python3.11/site-packages/grpc/_channel.py:1162\u001B[0m, in \u001B[0;36m_UnaryUnaryMultiCallable._blocking\u001B[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[0m\n\u001B[1;32m   1145\u001B[0m state\u001B[38;5;241m.\u001B[39mtarget \u001B[38;5;241m=\u001B[39m _common\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target)\n\u001B[1;32m   1146\u001B[0m call \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_channel\u001B[38;5;241m.\u001B[39msegregated_call(\n\u001B[1;32m   1147\u001B[0m     cygrpc\u001B[38;5;241m.\u001B[39mPropagationConstants\u001B[38;5;241m.\u001B[39mGRPC_PROPAGATE_DEFAULTS,\n\u001B[1;32m   1148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registered_call_handle,\n\u001B[1;32m   1161\u001B[0m )\n\u001B[0;32m-> 1162\u001B[0m event \u001B[38;5;241m=\u001B[39m call\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m   1163\u001B[0m _handle_event(event, state, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_deserializer)\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m state, call\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc._next_call_event\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc._next_call_event\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc._latent_event\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc._internal_latent_event\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001B[0m, in \u001B[0;36mgrpc._cython.cygrpc._next\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f18164002cfdb5f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
